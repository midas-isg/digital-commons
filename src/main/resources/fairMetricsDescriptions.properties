FM-Identifier-Field = Metric Identifier:
FM-Name-Field = Metric Name:
FM-Principle-Field = To which principle does it apply?
FM-Measured-Field = What is being measured?
FM-Why-Measure-Field = Why should we measure it?
FM-Must-Provided-Field = What must be provided?
FM-How-Measure-Field = How do we measure it?
FM-Valid-Result-Field = What is a valid result?
FM-Which-Relevant-Field = For which digital resource(s) is this relevant?
FM-Examples-Field = Examples of their application across types of digital resource:

FM-Identifier = FAIR Metrics should, themselves, be FAIR objects, and thus should have globally unique identifiers.
FM-Name = A human-readable name for the metric.
FM-Principle = Metrics should address only one sub-principle, since each FAIR principle is particular to one feature of a digital resource; metrics that address multiple principles are likely to be measuring multiple features, and those should be separated whenever possible.
FM-Measured = A precise description of the aspect of that digital resource that is going to be evaluated.
FM-Why-Measure = Describe why it is relevant to measure this aspect.
FM-Must-Provided = What information is required to make this measurement?
FM-How-Measure = In what way will that information be evaluated?
FM-Valid-Result = What outcome represents "success" versus "failure"?
FM-Which-Relevant = If possible, a metric should apply to all digital resources; however, some metrics may be applicable only to a subset. In this case, it is necessary to specify the range of resources to which the metric is reasonably applicable.
FM-Examples = Whenever possible, provide an existing example of success, and an example of failure.

FM-F1A-Column-Header = F1A
FM-F1B-Column-Header = F1B
FM-F2-Column-Header = F2
FM-F3-Column-Header = F3
FM-F4-Column-Header = F4
FM-A1.1-Column-Header = A1.1
FM-A1.2-Column-Header = A1.2
FM-A2-Column-Header = A2
FM-I1-Column-Header = I1
FM-I2-Column-Header = I2
FM-I3-Column-Header = I3
FM-R1.1-Column-Header = R1.1
FM-R1.2-Column-Header = R1.2


FM-F1A-Identifier = FM-F1A: https://purl.org/fair-metrics/FM_F1A
FM-F1A-URL = https://purl.org/fair-metrics/FM_F1A
FM-F1A-Name = Identifier Uniqueness
FM-F1A-Principle = F1 - (Meta) data are assigned globally unique and persistent identifiers
FM-F1A-Measured = Whether there is a scheme to uniquely identify the digital resource.
FM-F1A-Why-Measure = The uniqueness of an identifier is a necessary condition to unambiguously refer that resource, and that resource alone. Otherwise, an identifier shared by multiple resources will confound efforts to describe that resource, or to use the identifier to retrieve it. Examples of identifier schemes include, but are not limited to URN, IRI, DOI, Handle, trustyURI, LSID, etc. For an in-depth understanding of the issues around identifiers, please see http://dx.plos.org/10.1371/journal.pbio.2001414
FM-F1A-Must-Provided = URL to a registered identifier scheme.
FM-F1A-How-Measure = An identifier scheme is valid if and only if it is described in a repository that can register and present such identifier schemes (e.g. fairsharing.org).<br><br>Information about the identifier scheme must be presented with a machine-readable document containing the FM1 attribute with the URL to where the scheme is described.  see specification for implementation.
FM-F1A-Valid-Result = Present or Absent
FM-F1A-Which-Relevant = All
FM-F1A-Examples = <tr><td>Ontology</td><td><table><tbody><tr><td>Gene Ontology:</td><td>http://www.ebi.ac.uk/miriam/main/ datatypes/MIR:00000022</td></tr><tr><td>HISCO:</td><td>This resource has not described or registered their identifier scheme. A recommended course of action would be to XXX.</td></tr><tr><td>Model/format - RDFS:</td><td>https://fairsharing.org/bsg-s000283</td></tr><tr><td>Repository</td><td>JWS Online: https://www.ebi.ac.uk/miriam/main<br> /collections/MIR:00000130 <br> - DANS EASY: </td></tr></tbody></table></td></tr><td><tr>Database</td><td><table><tbody><tr><td>ArrayExpress:</td><td>https://fairsharing.org/biodbcore-000305</td></tr><tr><td>FAIRsharing will implement the FAIR Metric specification to provide a machine-readable link to the MIRIAM repository (for life science content)<td></tr></tbody></table><tr><td>API<table><tbody><tr><td>smartAPI's API</td><td>https://raw.githubusercontent.com/WebsmartAPI/smartAPI/master/docs/iodocs/smartapi.json<br>the smartAPI repository will provide accessible specification of the identifier scheme that is embedded in that metadata document.</td></tr></tbody></table><tr><td>Journal</td><td>http://www.nature.com/developers/documentation/metadata-resources/doi  <br>the web site will have to provide a machine-readable pointer to the official DOI specification.</td></tr></tbody><table></td></tr>
FM-F1A-Comments = A first version of this metric would focus on just checking a URL that resolves to a document. We can't verify that document. <br> A second version would indicate how to structure the data policy document with a particular section (similar to how the CC licenses now have a formal structure in RDF).<br> A third version would insist that that document and section is signed by an approved organization and made available in an appropriate repository.

FM-F1B-Identifier = FM-F1B: https://purl.org/fair-metrics/FM_F1B
FM-F1B-URL = https://purl.org/fair-metrics/FM_F1B
FM-F1B-Name = Identifier Persistence
FM-F1B-Principle = F1 - (Meta) data are assigned globally unique and persistent identifiers
FM-F1B-Measured = Whether there is a policy that describes what the provider will do in the event an identifier scheme becomes deprecated.
FM-F1B-Why-Measure = The change to an identifier scheme will have widespread implications for resource lookup, linking, and data sharing. Providers of digital resources must ensure that they have a policy to manage changes in their identifier scheme, with a specific emphasis on maintaining/redirecting previously generated identifiers.
FM-F1B-Must-Provided = A URL that resolves to a document containing the relevant policy.
FM-F1B-How-Measure = Use an HTTP GET on URL provided.
FM-F1B-Valid-Result = Present (a 200,202,203 or 206 HTTP response after resolving all and any prior redirects. e.g. 301 -> 302 -> 200 OK) or Absent (any other HTTP code).
FM-F1B-Which-Relevant = All
FM-F1B-Examples = for each of the 'canonical' data types, examples, if available. <br> @todo <br> <br> FAIR principles (scholarly publication in Nature Scientific Data)<br> https://www.doi.org/overview/DOI_article_ELIS3.pdf <br> http://www.nature.com/developers/documentation/metadata-resources/doi/ <br> <br> FAIR Principles (computable representation):  <br> https://github.com/FAIRDataInitiative/FAIR-principles#fair-principles <br> For DSA-certified repositories (example below of 3TU-Datacentre at Delft) the identifier persistence policy is described in the self assessment:<br> https://assessment.datasealofapproval.org/assessment_187/seal/pdf/ <br> <br>DOI Handbook - ensuring persistence:<br> http://www.doi.org/doi_handbook/6_Policies.html#6.5}.
FM-F1B-Comments = A first version of this metric would focus on just checking a URL that resolves to a document. We can't verify that document. <br>A second version would indicate how to structure the data policy document with a particular section (similar to how the CC licenses now have a formal structure in RDF).<br>A third version would insist that that document and section is signed by an approved organization and made available in an appropriate repository.

FM-F2-Identifier = FM-F2: https://purl.org/fair-metrics/FM_F2
FM-F2-URL = https://purl.org/fair-metrics/FM_F2
FM-F2-Name = Machine-Readability of Metadata
FM-F2-Principle = F2 - Data are described with rich metadata.
FM-F2-Measured = The availability of machine-readable metadata that describes a digital resource.
FM-F2-Why-Measure = This metric {does not} attempt to measure (or even define) 'Richness' - this will be defined in a future Metric.  This metric is intended to test the format of the metadata - machine readability of metadata makes it possible to optimize discovery. For instance, Web search engines suggest the use of particular structured metadata elements to optimize search. Thus, the machine-readability aspect can help people and machines find a digital resource of interest.
FM-F2-Must-Provided = A URL to a document that contains machine-readable metadata for the digital resource. Furthermore, the file format must be specified.
FM-F2-How-Measure = HTTP GET on the metadata URL. A response of [a 200,202,203 or 206 HTTP response after resolving all and any prior redirects. e.g. 301 -> 302 -> 200 OK] indicates that there is indeed a document. The second URL should resolve to the record of a registered file format (e.g. DCAT, DICOM, schema.org etc.) in a registry like FAIRsharing. Future ehnancements to FAIRSharing may include tags that indicate whether or not a given file format is generally- agreed to be machine-readable.
FM-F2-Valid-Result = Machine-readable or Machine-not-readable
FM-F2-Which-Relevant = All
FM-F2-Examples = This URL can resolve to:<br> - A record in a metadata registry relevant to your digital object (e.g. FAIRsharing.org, FAIR Data Point, smartAPI editor)<br> - Your metadata on an HTML web page using schema.org<br> - A FAIR Accessor...<br> <br> Semanticscience Integrated Ontology :   http://semanticscience.org/ontology/sio.owl   https://biosharing.org/bsg-s002686 <br> Example of a DANS metadata-record of an archived dataset:  https://easy.dans.knaw.nl/ui/datasets/id/easy-dataset:67859/tab/1  <br> smartAPI's API metadata: https://raw.githubusercontent.com/WebsmartAPI/smartAPI/master/docs/iodocs/smartapi.json  <br> Metadata record of a database:  - GEO https://fairsharing.org/biodbcore-000441   <br> Metadata record of a standard:  - RDF https://fairsharing.org/bsg-s000559  <br> Non-article Published Work<br> - my Zenodo Deposit for polyA (https://doi.org/10.5281/zenodo.47641)<br> - myExperiment Workflow (http://www.myexperiment.org/workflows/2999.html)<br> - Jupyter notebook on GitHub (https://github.com/VidhyasreeRamu/GlobalClimateChange/blob/master/GlobalWarmingAnalysis.ipynb).
FM-F2-Comments = None

FM-F3-Identifier = FM-F3: https://purl.org/fair-metrics/FM_F3
FM-F3-URL = https://purl.org/fair-metrics/FM_F3
FM-F3-Name = Resource Identifier in Metadata
FM-F3-Principle = F3 - metadata clearly and explicitly include the identifier of the data it describes.
FM-F3-Measured = Whether the metadata document contains the globally unique and persistent identifier for the digital resource.
FM-F3-Why-Measure = The discovery of digital object should be possible from its metadata. For this to happen, the metadata must explicitly contain the identifier for the digital resource it describes, and this should be present in the form of a qualified reference, indicating some manner of 'about' relationship, to distinguish this identifier from the numerous others that will be present in the metadata.<br><br> In addition, since many digital objects cannot be arbitrarily extended to include references to their metadata, in many cases the only means to discover the metadata related to a digital object will be to search based on the GUID of the digital object itself.
FM-F3-Must-Provided = The GUID of the metadata and the GUID of the digital resource it describes.
FM-F3-How-Measure = Parsing the metadata for the given digital resource GUID.
FM-F3-Valid-Result = Present or absent
FM-F3-Which-Relevant = All
FM-F3-Examples = None
FM-F3-Comments = In practice there are issues related to the format of the metadata document that might make a simple string search impossible.  For example, relative URLs in HTML and qnames in XML/RDF.  We should engage in some community discussion about exactly how to execute this Metric.

FM-F4-Identifier = FM-F4: https://purl.org/fair-metrics/FM_F4
FM-F4-URL = https://purl.org/fair-metrics/FM_F4
FM-F4-Name = Indexed in a Searchable Resource
FM-F4-Principle = F4 - (meta)data are registered or indexed in a searchable resource.
FM-F4-Measured = The degree to which the digital resource can be found using  web-based search engines.
FM-F4-Why-Measure = Most people use a search engine to initiate a search for a particular digital resource of interest. If the resource or its metadata are not indexed by web search engines, then this would substantially diminish an individual's ability to find and reuse it. Thus, the ability to discover the resource should be tested using i) its identifier, ii) other text-based metadata.
FM-F4-Must-Provided = The persistent identifier of the resource and one or more URLs that give search results of different search engines.
FM-F4-How-Measure = We perform an HTTP GET on the URLs provided and attempt to to find the persistent identifier in the page that is returned. A second step might include following each of the top XX hits and examine the resulting documents for presence of the identifier.
FM-F4-Valid-Result = true - the persistent identifier was found in the search results.
FM-F4-Which-Relevant = All
FM-F4-Examples = - my Zenodo Deposit for polyA <br>  (https://doi.org/10.5281/zenodo.47641)<br>  Test Query:  10.5281/zenodo.47641  orthology<br>  GOOGLE: Pass (#1 hit);  BING:  Fail (no hits); Yahoo: Fail (no hits); Baidu: Pass (#1 hit)  <br>  Test Query: 'protein domain orthology RNA Processing'<br>  Google:  ~Pass (Hit #13 ); BING:  Fail (not in top 40); Yahoo:  Fail:  (Not in top 40); Baidu: Pass (#1 Hit)<br>  - myExperiment Workflow (http://www.myexperiment.org/workflows/2969.html)<br>  Test Query: 'workflow common identifiers EMC ontology'<br>  GOOGLE:  Pass (#2 and #5 hit); BING: Fail (not in top 40, though OTHER workflows were found in top 10!); Yahoo: Fail (not in top 40, though other workflows found in top 10); Baidu: ~Pass (5/10 pages contained a link to the workflow, but the workflow itself was not discovered)<br>  - Jupyter notebook on GitHub (https://github.com/<br> VidhyasreeRamu/GlobalClimateChange/blob<br> /master/GlobalWarmingAnalysis.ipynb)<br>  Test Query:  'github python climate change earth surface temperature'<br>  Google:  Fail (not in top 40; other similar Jupyter notebooks found in github); Bing: Fail (not in top 40... but MANY links to Microsoft Surface! LOL!); Yahoo:  Fail (not in top 40); Baidu: Fail (not even a github hit in top 40!).
FM-F4-Comments = None

FM-A1.1-Identifier = FM-A1.1: https://purl.org/fair-metrics/FM_A1.1
FM-A1.1-URL = https://purl.org/fair-metrics/FM_A1.1
FM-A1.1-Name = Access Protocol
FM-A1.1-Principle = A1.1 - the protocol is open, free, and universally implementable.
FM-A1.1-Measured = The nature and use limitations of the access protocol.
FM-A1.1-Why-Measure = Access to a resource may be limited by the specified communication protocol. In particular, we are worried about access to technical specifications and any costs associated with implementing the protocol. Protocols that are closed source or that have royalties associated with them could prevent users from being able to obtain the resource.
FM-A1.1-Must-Provided = i) A URL to the description of the protocol<br>ii) true/false as to whether the protocol is open source<br>iii) true/false as to whether the protocol is (royalty) free.
FM-A1.1-How-Measure = Do an HTTP get on the URL to see if it returns a valid document. Ideally, we would have a universal database of communication protocols from which we can check this URL. We also check whether questions 2 and 3 are true or false.
FM-A1.1-Valid-Result = The HTTP GET on the URL should return a 200,202,203 or 206 HTTP response after resolving all and any prior redirects. e.g. 301 -> 302 -> 200 OK. The other two should be true/false.
FM-A1.1-Which-Relevant = All
FM-A1.1-Examples = None
FM-A1.1-Comments = None

FM-A1.2-Identifier = FM-A1.2: https://purl.org/fair-metrics/FM_A1.2
FM-A1.2-URL = https://purl.org/fair-metrics/FM_A1.2
FM-A1.2-Name = Access Authorization
FM-A1.2-Principle = A1.2 - the protocol allows for an authentication and authorization procedure, where necessary.
FM-A1.2-Measured = Specification of a protocol to access restricted content.
FM-A1.2-Why-Measure = Not all content can be made available without restriction. For instance, access and distribution of personal health data may be restricted by law or by organizational policy. In such cases, it is important that the protocol by which such content can be accessed is fully specified. Ideally, electronic content can be obtained first by applying for access. Once the requester is formally authorized to access the content, they may receive it in some electronic means, for instance by obtaining an download URL, or through a more sophisticated transaction mechanism (e.g. authenticate, authorize), or by any other means. The goal should be to reduce the time it takes for valid requests to be fulfilled.
FM-A1.2-Must-Provided = i) true/false concerning whether authorization is needed<br>ii) a URL that resolves to a description of the process to obtain access to restricted content.
FM-A1.2-How-Measure = Computational validation of the data provided.
FM-A1.2-Valid-Result = A valid answer contains a true or false for the first question. if true, an HTTP GET on the URL provided should return a 200, 202, 203, or 206 HTTP Response after resolving all redirects.
FM-A1.2-Which-Relevant = All
FM-A1.2-Examples = None
FM-A1.2-Comments = None

FM-A2-Identifier = FM-A2: https://purl.org/fair-metrics/FM_A2
FM-A2-URL = https://purl.org/fair-metrics/FM_A2
FM-A2-Name = Metadata Longevity
FM-A2-Principle = A2 - metadata are accessible, even when the data are no longer available.
FM-A2-Measured = The existence of metadata even in the absence/removal of data.
FM-A2-Why-Measure = Cross-references to data from third-party's FAIR data and metadata will naturally degrade over time, and become 'stale links'.  In such cases, it is important for FAIR providers to continue to provide descriptors of what the data was to assist in the continued interpretation of those third-party data.  As per FAIR Principle F3, this metadata remains discoverable, even in the absence of the data, because it contains an explicit reference to the IRI of the data.
FM-A2-Must-Provided = URL to a formal metadata longevity plan.
FM-A2-How-Measure = Resolve the URL.
FM-A2-Valid-Result = Successful resolution<br> - Returns a document that represents a plan or policy of some kind<br> - Preferably certified (e.g. DSA).
FM-A2-Which-Relevant = All metadata
FM-A2-Examples = None
FM-A2-Comments = None

FM-I1-Identifier = FM-I1: https://purl.org/fair-metrics/FM_I1
FM-I1-URL = https://purl.org/fair-metrics/FM_I1
FM-I1-Name = Use a Knowledge Representation Language
FM-I1-Principle = I1 - (meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation.
FM-I1-Measured = Use of a formal, accessible, shared, and broadly applicable language for knowledge representation.
FM-I1-Why-Measure = The unambiguous communication of knowledge and meaning (what symbols are, and how they relate to one another) necessitates the use of languages that are capable of representing these concepts in a machine-readable manner.
FM-I1-Must-Provided = URL to the specification of the language.
FM-I1-How-Measure = - The language must have a BNF (or other specification language) <br>  - The URL resolves (accessible) <br>  - The document has an IANA media-type (i.e. it is sufficiently widely-accepted and shared that it has been registered) <br>  - The language can be arbitrarily extended (e.g. PDBml can be used to represent knowledge, but only about proteins).
FM-I1-Valid-Result = BNF (or other?) found, Media-type of the document is registered in FAIRSharing. <br><br> Future:  FAIRSharing has tags to indicate constrained vs. extendable languages?
FM-I1-Which-Relevant = All
FM-I1-Examples = None
FM-I1-Comments = michel: there must be a syntax and associated semantics for that language.  This is sufficient <br>  mark: there needs to be some identity or denotation in the language; ('vanilla') xml and json are not FAIR, so should fail this test<br>  <br>  *** can you (i) identify elements and (ii) make statements about them, and iii) is there a formally defined interpretation for that <br>-> HTML fails; PDF fails <br>  shared<br>  -> that there are many users of the language<br>  . acknowledged within your community<br>   -> hard to prove.<br>  . could we use google to query for your filetype (can't discriminate between different models)<br>  -> has a media type<br>  --> This SHOULD be stated as a IANA code [IANA-MT]<br>  standardization of at least this listing process is a good measure of 'sharedness'<br>  broadly applicable<br>  . that the language is extensible to a domain of interest<br>  . you can define your own elements in accordance with the semantics of the language<br>  <br>  gff3 is not in the IANA list -> what steps would the community need to execute to be listed here? cases like GFF, PDB are not broadly applicable <br>  biopax -> is defined vnd.biopax.rdf+xml and built on rdf -> allows users to create new elements and relate them <br>  jpg -> widely used, registered, but primarily for image content<br>  pdf -> registered, enables users to create their own dictionary.

FM-I2-Identifier = FM-I2: https://purl.org/fair-metrics/FM_I2
FM-I2-URL = https://purl.org/fair-metrics/FM_I2
FM-I2-Name = Use FAIR Vocabularies
FM-I2-Principle = I2 - (meta)data use vocabularies that follow FAIR principles.
FM-I2-Measured = The metadata values and qualified relations should themselves be FAIR, for example, terms from open, community-accepted vocabularies published in an appropriate knowledge-exchange format.
FM-I2-Why-Measure = It is not possible to unambiguously interpret metadata represented as simple keywords or other non-qualified symbols.  For interoperability, it must be possible to identify data that can be integrated like-with-like.  This requires that the data, and the provenance descriptors of the data, should (where reasonable) use vocabularies and terminologies that are, themselves, FAIR.
FM-I2-Must-Provided = IRIs representing the vocabularies used for (meta)data.
FM-I2-How-Measure = Resolve IRIs, check FAIRness of the returned document(s).
FM-I2-Valid-Result = Successful resolution; document is amenable to machine-parsing and identification of terms within it.  It may be possible to use FAIRSharing to validate these vocabularies.
FM-I2-Which-Relevant = All
FM-I2-Examples = None
FM-I2-Comments = michel: there must be a syntax and associated semantics for that language.  This is sufficient <br>  mark: there needs to be some identity or denotation in the language; ('vanilla') xml and json are not FAIR, so should fail this test<br>  <br>  *** can you (i) identify elements and (ii) make statements about them, and iii) is there a formally defined interpretation for that   -> HTML fails; PDF fails <br>  shared<br>  -> that there are many users of the language<br>  . acknowledged within your community<br>   -> hard to prove.<br>  . could we use google to query for your filetype (can't discriminate between different models)<br>  -> has a media type<br>  --> This SHOULD be stated as a IANA code [IANA-MT]<br>  standardization of at least this listing process is a good measure of 'sharedness'<br>  broadly applicable<br>  . that the language is extensible to a domain of interest<br>  . you can define your own elements in accordance with the semantics of the language<br>  <br>  gff3 is not in the IANA list -> what steps would the community need to execute to be listed here? cases like GFF, PDB are not broadly applicable <br>  biopax -> is defined vnd.biopax.rdf+xml and built on rdf -> allows users to create new elements and relate them <br>  jpg -> widely used, registered, but primarily for image content<br>  pdf -> registered, enables users to create their own dictionary.

FM-I3-Identifier = FM-I3: https://purl.org/fair-metrics/FM_I3
FM-I3-URL = https://purl.org/fair-metrics/FM_I3
FM-I3-Name = Use Qualified References
FM-I3-Principle = I3 - (meta)data include qualified references to other (meta)data.
FM-I3-Measured = Relationships within (meta)data, and between local and third-party data, have explicit and 'useful' semantic meaning.
FM-I3-Why-Measure = One of the reasons that HTML is not suitable for machine-readable knowledge representation is that the hyperlinks between one document and another do not explain the nature of the relationship - it is 'unqualified'.  For Interoperability, the relationships within and between data must be more semantically rich than 'is (somehow) related to'.<br>  <br>  Numerous ontologies include richer relationships that can be used for this purpose, at various levels of domain-specificity.  For example, the use of skos for terminologies (e.g. exact matches), or the use of SIO for genomics (e.g. 'has phenotype' for the relationship between a variant and its phenotypic consequences).  The semantics of the relationship do not need to be 'strong' - for example, 'objectX  wasFoundInTheSameBoxAs objectY' is an acceptable qualified reference<br>  <br>  Similarly, dbxrefs must be predicated with a meaningful relationship  what is the nature of the cross-reference?<br>  <br>  Finally, data silos thwart interoperability.  Thus, we should reasonably expect that some of the references/relations point outwards to other resources, owned by third-parties; this is one of the requirements for 5 star linked data.
FM-I3-Must-Provided = Linksets (in the formal sense) representing part or all of your resource.
FM-I3-How-Measure = The linksets must have qualified references<br> At least one of the links must be in a different Web domain (or the equivalent of a different namespace for non-URI identifiers).
FM-I3-Valid-Result = - References are qualified<br> - Qualities are beyond 'Xref' or 'is related to'<br> - One of the cross-references points outwards to a distinct namespace.
FM-I3-Which-Relevant = All
FM-I3-Examples = None
FM-I3-Comments = None

FM-R1.1-Identifier = FM-R1.1: https://purl.org/fair-metrics/FM_R1.1
FM-R1.1-URL = https://purl.org/fair-metrics/FM_R1.1
FM-R1.1-Name = Accessible Usage License
FM-R1.1-Principle = R1.1 - (meta)data are released with a clear and accessible data usage license.
FM-R1.1-Measured = The existence of a license document, for BOTH (independently) the data and its associated metadata, and the ability to retrieve those documents.
FM-R1.1-Why-Measure = A core aspect of data reusability is the ability to determine, unambiguously and with relative ease, the conditions under which you are allowed to reuse the (meta)data.  Thus, FAIR data providers must make these terms openly available.  This applies both to data (e.g. for the purpose of third-party integration with other data) and for metadata (e.g. for the purpose of third-party indexing or other administrative metrics).
FM-R1.1-Must-Provided = IRI of the license (e.g. its URL) for the data license and for the metadata license.
FM-R1.1-How-Measure = Resolve the IRI(s) using its associated resolution protocol.
FM-R1.1-Valid-Result = A document containing the license information.
FM-R1.1-Which-Relevant = All
FM-R1.1-Examples = None
FM-R1.1-Comments = None

FM-R1.2-Identifier = FM-R1.2: https://purl.org/fair-metrics/FM_R1.2
FM-R1.2-URL = https://purl.org/fair-metrics/FM_R1.2
FM-R1.2-Name = Detailed Provenance
FM-R1.2-Principle = R1.2 - (meta)data are associated with detailed provenance
FM-R1.2-Measured = That there is provenance information associated with the data, covering at least two primary types of provenance information:<br>  - Who/What/When produced the data (i.e. for citation)<br>  - Why/How was the data produced (i.e. to understand context and relevance of the data).
FM-R1.2-Why-Measure = Reusability is not only a technical issue; data can be discovered, retrieved, and even be machine-readable, but still not be reusable in any rational way.  Reusability goes beyond 'can I reuse this data?' to other important questions such as 'may I reuse this data?', 'should I reuse this data', and 'who should I credit if I decide to use it'?
FM-R1.2-Must-Provided = Several IRIs -  at least one of these points to one of the vocabularies used to describe citational provenance (e.g. dublin core).  At least one points to one of the vocabularies (likely domain-specific) that is used to describe contextual provenance (e.g. EDAM).
FM-R1.2-How-Measure = We resolve the IRI according to their associated protocols.<br><br>In the future, we may be able to cross-reference these with FAIRSharing to confirm that they are 'standard', and perhaps even distinguish citation vs. domain specific.
FM-R1.2-Valid-Result = IRI 1 should resolve to a recognized citation provenance standard such as Dublin Core.<br>  IRI 2 should resolve to some vocabulary that itself passes basic tests of FAIRness.
FM-R1.2-Which-Relevant = All
FM-R1.2-Examples = None
FM-R1.2-Comments = Many data formats have fields specifically for Provenance information.  -> could fairsharing curate these 4 fields? for every format and vocabulary? <br> Some formats do not have these fields.  For example, although gff can have arbitrary headers, the standard itself does not provide specific fields to capture detailed provenance. It therefore would.


Findable =  Data and metadata are easy to find by both humans and computers. Machine readable metadata is essential for automatic discovery of relevant datasets and services, and for this reason are essential to the FAIRification process.
Accessible = Limitations on the use of data, and protocols for querying or copying data are made explicit for both humans and machines.
Interoperable = The computer can interpret the data, so that they can be automatically combined with other data. There is a historical trend in computer science toward increased interoperation (for example, between different hardware designs, operating systems, programming languages, and communication protocols). Data interoperability can be seen as the ragged edge of this long-term trend. However, data interoperation is a non-trivial problem and the "I" will require the most creative effort in making FAIR Data.
Reusable = Data and metadata are sufficiently well described for both humans and computers, so that they can be replicated or combined in future research.